---
title: "Exploratory Analysis of r/AgainstHateSubreddits"
author: "Dulshani"
date: "16/06/2021"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = TRUE
)

library(arrow) # data retrieval from storage
library(gridExtra) # combine multiple plots
library(ggrepel) # intelligent label placement
library(tidyverse) # dataframe manipulation

source('utility_functions.R')
```


```{r read_data}
ahs <- read_reddit_data('AgainstHateSubreddits')
```

```{r}
# No of total posts (before pre-processing)
dim(ahs)
```

```{r}
ahs_preprocessed <- ahs %>%
  # Remove meta, bot and deleted posts
  filter(link_flair_text != 'Meta', selftext != '[removed]', selftext != '[deleted]', author != 'AutoModerator') %>% 
        # Try to derive subreddit from link_flair_text
  mutate(derived_subreddit = str_extract(str_to_lower(link_flair_text), 'r\\/[a-z0-9_]+'), 
        # If it fails, try to derive subreddit from link_flair_text
         derived_subreddit = ifelse(is.na(derived_subreddit), 
                                    str_extract(str_to_lower(title), 'r\\/[a-z0-9_]+'), 
                                    derived_subreddit),
        derived_subreddit = str_replace(derived_subreddit, 'r\\/', ''),
        derived_subreddit = str_replace(derived_subreddit, 'fds', 'femaledatingstrategy')
        #derived_subreddit = factor(derived_subreddit)
        ) %>%
  filter(!is.na(derived_subreddit), derived_subreddit != 'r/againsthatesubreddits') %>% # Remove posts with no derived subreddits
  filter(created_utc >= '2018-04-01' & created_utc <= '2021-04-30')

dim(ahs_preprocessed)
# This task could be done better by using word embeddings to identify the pattern, rather than by using regex.
# Potential improvement for future 
```


```{r}
head(ahs_preprocessed)
```

```{r}
(derived_subreddit_count <- ahs_preprocessed %>%
  group_by(derived_subreddit) %>%
  summarise(n = n(), first_report = min(created_utc), last_report = max(created_utc), total_score = sum(score)) %>%
  mutate(time_difference = last_report - first_report + 1,
         normalised_n = n/as.double(time_difference))  %>%
 # arrange(derived_subreddit)
  arrange(desc(total_score))
 )
```

```{r}
length(derived_subreddit_count$derived_subreddit)
```



```{r}
summary(derived_subreddit_count)
```



```{r}
# Histogram with number of reports for subreddits
p1 <- ggplot(data = derived_subreddit_count, map = aes(x = n)) +
  scale_x_continuous(trans = 'log10') +
  geom_histogram(boundary = 0, bins = 10, fill = '#99a666', alpha = 0.5) +
  geom_point(data = subset(derived_subreddit_count, n > 25), 
             aes(n, 1),
             size = 1, 
             shape = 20, 
             color = '#96568b'
             ) +
  geom_text_repel(data = subset(derived_subreddit_count, n > 25),
                color = "#96568b",
                mapping = aes(x = n, y = 0, label = derived_subreddit),
                size = 3,
                force_pull   = 0, 
                nudge_y      = 200,
                direction    = "x",
                angle        = 90,
                hjust        = 0,
                segment.size = 0.2,
                max.iter = 1e4, 
                max.time = 1
                ) +
  labs(title = "Post Distribution", x = "# Posts", y = "# Subreddits") +
  theme_minimal()
```

```{r}
# Histogram with total score for subreddits
p2 <- ggplot(data = derived_subreddit_count, map = aes(x = total_score)) +
  geom_histogram(boundary = 0, bins = 20, fill = '#99a666', alpha = 0.5) +
  scale_x_continuous(trans = 'sqrt') +
  geom_point(data = subset(derived_subreddit_count, total_score > 10000), 
             aes(total_score, 1),
             size = 1, 
             shape = 20, 
             color = '#96568b'
             ) +
  geom_text_repel(data = subset(derived_subreddit_count, total_score > 10000),
                color = "#96568b",
                mapping = aes(x = total_score, y = 0, label = derived_subreddit),
                size = 3,
                force_pull   = 0, 
                nudge_y      = 200,
                direction    = "x",
                angle        = 90,
                hjust        = 0,
                segment.size = 0.2,
                max.iter = 1e4, 
                max.time = 1
                ) +
  labs(title = "Total Score Distribution", x = "Total Score (Upvotes - Downvotes) across all Reports", y = "# Subreddits") +
  theme_minimal()
```

```{r fig.height = 7}
grid.arrange(p1, p2, nrow = 2)
```




```{r}
# Main report reasons for selected subreddits
selected_subreddits <- derived_subreddit_count %>%
  filter(total_score > 10000)

report_reason <- ahs_preprocessed %>%
  filter(derived_subreddit %in% selected_subreddits$derived_subreddit,
         !str_count(str_to_lower(link_flair_text), 'r\\/[a-z0-9_]+') > 0,
         !link_flair_text %in% c("removed - repost, see sticky", "ðŸ¦€ Hate Sub Banned ðŸ¦€", "SPLC REPORT", "removed", "Brigaded by Unpopular Opinion.", "", "ðŸš¨ Ban Evasion Sub ðŸš¨",
                                 "Other", "Food for Thoughts")
         ) %>%
  group_by(derived_subreddit, link_flair_text) %>%
  summarise(n = n()) 

unique(report_reason$link_flair_text)
```
```{r fig.height = 5}
subreddit_names <- c("AltRightChristian", "Anarcho_Capitalism", "AskAConservative", "AverageRedditor", "Chodi", 
                      "Conservative", "Conspiracy", "CringeAnarchy", "DonaldTrump",  "FemaleDatingStrategy", "GenderCritical", 
                      "MetaCanada", "MGTOW", "MillionDollarExtreme", "ProtectAndServe", "The_Donald", "Tucker_Carlson","UnpopularOpinion")

ggplot(report_reason, aes(derived_subreddit, link_flair_text, fill = n)) + 
  geom_tile() +
  labs(title = "Reason provided for reporting on AHS", x = "", fill = "# Reports", y ="") +
  theme_minimal() +
  theme(plot.title = element_text(size = 11),
      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  scale_fill_gradient(low = "#dfecd1", high = "#0b383b") +
  scale_x_discrete(labels = subreddit_names)
```

